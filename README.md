# Data Science Preparation

### Preliminaries

 - If you are just beginning with ML & Data Science, a good first place to start will be [Andrew Ng Coursera ML course](https://www.coursera.org/learn/machine-learning). Finish at least the first few weeks.

 - If you have already done the Andrew Ng course, you might want to brush up on the concepts through these notes. [Stanford Machine Learning, holehouse.org](https://www.holehouse.org/mlclass/)

 - If you want to make a list of important interview topics head over to this article. [Machine Learning Cheatsheet](https://medium.com/swlh/cheat-sheets-for-machine-learning-interview-topics-51c2bc2bab4f)

### Video resources

These videos work really well when you wanna take a break between your intense interview prep or at bedtime when you just want something to scroll at. Now you may proceed binge-watching these ML/Data Science videos. Enjoy :)

**P.S. Ctrl+F to serach for relevant keywords.**

### Courses & Resources
 - [ ] <A HREF="https://towardsdatascience.com/top-10-resources-to-become-a-data-scientist-in-2020-99a315194701">Become a Data Scientist in 2020 with these 10 resources</A>
 - [ ] <A HREF="https://www.coursera.org/specializations/data-science-python?ranMID=40328&ranEAID=lVarvwc5BD0&ranSiteID=lVarvwc5BD0-_4L3mvw.I6oY9SNPHAtR2Q&siteID=lVarvwc5BD0-_4L3mvw.I6oY9SNPHAtR2Q&utm_content=2&utm_medium=partners&utm_source=linkshare&utm_campaign=lVarvwc5BD0">Applied Data Science with Python | Coursera</A>
 - [ ] <A HREF="https://towardsdatascience.com/minimal-pandas-subset-for-data-scientists-6355059629ae">Minimal Pandas Subset for Data Scientists - Towards Data Science</A>
 - [ ] <A HREF="https://towardsdatascience.com/pythons-one-liner-graph-creation-library-with-animations-hans-rosling-style-f2cb50490396">Python’s One Liner graph creation library with animations Hans Rosling Style</A>
 - [ ] <A HREF="https://towardsdatascience.com/3-awesome-visualization-techniques-for-every-dataset-9737eecacbe8">3 Awesome Visualization Techniques for every dataset</A>
 - [ ] <A HREF="https://www.coursera.org/learn/inferential-statistics-intro?ranMID=40328&ranEAID=lVarvwc5BD0&ranSiteID=lVarvwc5BD0-ydEVG6k5kidzLtNqbbVQvQ&siteID=lVarvwc5BD0-ydEVG6k5kidzLtNqbbVQvQ&utm_content=2&utm_medium=partners&utm_source=linkshare&utm_campaign=lVarvwc5BD0">Inferential Statistics | Coursera</A>
 - [ ] <A HREF="https://www.coursera.org/specializations/aml?ranMID=40328&ranEAID=lVarvwc5BD0&ranSiteID=lVarvwc5BD0-_1LkRNzPhJ43gzMHQzcbag&siteID=lVarvwc5BD0-_1LkRNzPhJ43gzMHQzcbag&utm_content=2&utm_medium=partners&utm_source=linkshare&utm_campaign=lVarvwc5BD0">Advanced Machine Learning | Coursera</A>
 - [ ] <A HREF="https://www.coursera.org/specializations/deep-learning?ranMID=40328&ranEAID=lVarvwc5BD0&ranSiteID=lVarvwc5BD0-m3SBadPJeg1Z1rWVng39OQ&siteID=lVarvwc5BD0-m3SBadPJeg1Z1rWVng39OQ&utm_content=2&utm_medium=partners&utm_source=linkshare&utm_campaign=lVarvwc5BD0">Deep Learning | Coursera</A>
 - [ ] <A HREF="https://www.coursera.org/learn/deep-neural-networks-with-pytorch?ranMID=40328&ranEAID=lVarvwc5BD0&ranSiteID=lVarvwc5BD0-Kb0qPiTtTFPC3kMQZlnqpg&siteID=lVarvwc5BD0-Kb0qPiTtTFPC3kMQZlnqpg&utm_content=2&utm_medium=partners&utm_source=linkshare&utm_campaign=lVarvwc5BD0">Deep Neural Networks with PyTorch | Coursera</A>
 - [ ] <A HREF="https://www.youtube.com/watch?v=7YuTmLvs1Dc">Data Science Interview Questions | Data Science Interview Questions and Answers with Tips</A>
 - [ ] <A HREF="http://www.holehouse.org/mlclass/">Machine Learning - complete course notes</A>

### SQL
Quickly go through the tutorial pages, you need not cram anything. Soon after, solve all the Hackerrank questions (in sequence, without skipping). Refer back to any of the tutorials or look up the discussion forum when stuck. You will learn more effectively this way and applying the various clauses will boost your recall.

- [ ] <A HREF="https://www.w3schools.com/sql/default.asp">SQL Tutorial Series</A>
- [ ] <A HREF="https://www.hackerrank.com/domains/sql">Hackerrank SQL Practice Questions</A>

### Probablility
 - [ ] <A HREF="https://www.youtube.com/watch?v=pYxNSUDSFH4">Probability vs Likelihood</A>
 - [ ] <A HREF="https://www.youtube.com/watch?v=Dn6b9fCIUpM">Maximum Likelihood For the Normal Distribution, step-by-step!</A>
 - [ ] <A HREF="https://www.youtube.com/watch?v=O2L2Uv9pdDA">Naive Bayes</A>
 - [ ] <A HREF="https://www.youtube.com/watch?v=sHRBg6BhKjI">Why Dividing By N Underestimates the Variance</A>
 - [ ] <A HREF="https://www.youtube.com/watch?v=YAlJCEDH2uY">The Central Limit Theorem</A>
 - [ ] <A HREF="https://www.youtube.com/watch?v=H3EjCKtlVog">Gaussian Naive Bayes</A>
 - [ ] <A HREF="https://www.youtube.com/watch?v=qtaqvPAeEJY">Covariance and Correlation Part 1: Covariance</A>
 - [ ] <A HREF="https://www.youtube.com/watch?v=iQoXFmbXRJA">Expectation Maximization: how it works</A>
 - [ ] <A HREF="https://www.youtube.com/watch?v=I4dkEALQv34">Bayesian Inference: An Easy Example</A>

### Linear Algebra
 - [ ] <A HREF="https://m.youtube.com/watch?feature=youtu.be&v=PFDu9oVAE-g">Eigenvectors and eigenvalues | Essence of linear algebra, chapter 14</A>

### Distributions
 - [ ] <A HREF="https://www.youtube.com/watch?v=5ptp4naoYEo">(1) Exponential and Laplace Distributions</A>
 - Gamma
 - Exponential
 - Students' T
 
### Inferential Statistics

:note:

<details> :notebook:
  <summary>P-values</summary>
  <ul>
   <li> 0 <= p-value <= 1
   <li> The closer the p-value to 0, the more the confidence that the null hypothesis (that there is no difference between two things) is false.
   <li> Threshold for making the decision: 0.05. This means that if there is no difference between the two things, then and the same experiment is repeated a bunch of times, then only 5% of them would yield a wrong decision.
   <li> In essence, 5% of the experiments, where the differences come from weird random things, will generate a p-value less that 0.05.
   <li> Thus, we should obtain large p-values if the two things being compared are identical.
   <li> Getting a small p-value even when there is no difference is known as a False positive.'
   <li> If it is extremely important when we say that the two things are different, we use a smaller threshold like 0.1%.
   <li> A small p-value does not imply that the difference between the two things is large.
  </ul>
</details>

<details>
  <summary>Error Types</summary>
  <ul>
   <li> Type-1 error: Incorrectly reject null (False positive)
   <li> Alpha: Prob(type-1 error) (aka level of significance)
   <li> Type-2 error: Fail to reject when you should have rejected null hypothesis (False negative)
   <li> Beta: Prob(type-2 error)
   <li> Power: Prob(Finding difference between when when it truly exists) = 1 - beta
   <li> Having power > 80% for a study is good. Calculated before study is conducted based on projections.
   <li> P-value: Prob(obtaining a result as extreme as the current one, assuming null is true)
   <li> Low p-value -> reject null hypothesis, high p-value -> fail to reject hypothesis
   <li> If p-value < alpha -> study was statistically significant. Alpha = 0.05 usually
  </ul>
</details>
 
<details>
  <summary>Statistical Tests</summary>
  <ul>
   <li> t-Test: compares 2 means
   <li> ANOVA test: compares >2 means
   <li> Chi-squared test: compares categorical variables
   <li> Shapiro Wilk test: test if a random sample comes from a normal distribution
   <li> Kolmogorov-Smirnov Goodness of Fit test: compares data with a known distribution to check if they have the same distribution
  </ul> 
</details>
 
 - [ ] <A HREF="https://www.youtube.com/watch?v=YSwmpAmLV2s">Null Hypothesis, p-Value, Statistical Significance, Type 1 Error and Type 2 Error</A>
 - [ ] <A HREF="https://www.youtube.com/watch?v=0oc49DyA3hU">Hypothesis Testing and The Null Hypothesis</A>
 - [ ] <A HREF="https://www.youtube.com/watch?v=JQc3yx0-Q9E">How to calculate p-values</A>
 - [ ] <A HREF="https://www.youtube.com/watch?v=5Z9OIYA8He8">P Values, clearly explained</A>
 - [ ] <A HREF="https://www.youtube.com/watch?v=vemZtEM63GY">p-values: What they are and how to interpret them</A>
 - [ ] <A HREF="https://www.youtube.com/watch?v=VK-rnA3-41c">Intro to Hypothesis Testing in Statistics - Hypothesis Testing Statistics Problems &amp; Examples</A>
 - [ ] <A HREF="https://www.youtube.com/watch?v=dpGmVV0-4jc">Idea behind hypothesis testing | Probability and Statistics</A>
 - [ ] <A HREF="https://www.youtube.com/watch?v=_3_6wjycJdk">Examples of null and alternative hypotheses | AP Statistics</A>
 - [ ] <A HREF="https://www.youtube.com/watch?v=TqOeMYtOc1w">Confidence Intervals</A>
 - [ ] <A HREF="https://www.youtube.com/watch?v=KS6KEWaoOOE">P-values and significance tests | AP Statistics</A>
 - [ ] <A HREF="https://towardsdatascience.com/feature-selection-correlation-and-p-value-da8921bfb3cf">Feature selection — Correlation and P-value | by Vishal R | Towards Data Science</A>
 
### Statistical Tests
 - [ ] <A HREF="https://www.youtube.com/watch?v=DEkPZv5ppHI">Z-Statistics vs. T-Statistics</A>
 - [ ] <A HREF="https://www.youtube.com/watch?v=zJ8e_wAWUzE">Hypothesis Testing Problems Z Test & T Statistics One & Two Tailed Tests 2</A>
 - [ ] <A HREF="https://www.youtube.com/watch?v=hpWdDmgsIRE">Contingency table chi-square test | Probability and Statistics</A>
 - [ ] <A HREF="https://towardsdatascience.com/6-ways-to-test-for-a-normal-distribution-which-one-to-use-9dcf47d8fa93">6 ways to test for a Normal Distribution — which one to use? (Kolmogorov Smirnov test, Shapiro Wilk test)</A>

### Linear Regression & Logistic Regression
 - [ ] <A HREF="https://www.youtube.com/watch?v=yIYKR4sgzI8">Logistic Regression</A>
 - [ ] <A HREF="https://www.youtube.com/watch?v=lng4ZgConCM">R-squared or coefficient of determination | Regression | Probability and Statistics</A>
 - [ ] <A HREF="https://www.youtube.com/watch?v=OCwZyYH14uw">Linear Regression vs Logistic Regression | Data Science Training | Edureka</A>
 - [ ] <A HREF="https://www.youtube.com/watch?v=Q-TtIPF0fCU">Regression and R-Squared (2.2)</A>
 - [ ] <A HREF="https://www.youtube.com/watch?v=nk2CQITm_eo">Linear Models Pt.1 - Linear Regression</A>
 - [ ] <A HREF="https://www.youtube.com/watch?v=GhrxgbQnEEU">How To... Perform Simple Linear Regression by Hand</A>
 - [ ] <A HREF="https://www.kaggle.com/shashankasubrahmanya/missing-data-imputation-using-regression">Missing Data Imputation using Regression | Kaggle</A>
 - [ ] <A HREF="https://www.youtube.com/watch?v=xZ_z8KWkhXE">Covariance and Correlation Part 2: Pearson&#39;s Correlation</A>
 - [ ] <A HREF="https://www.youtube.com/watch?v=2AQKmw14mHM">R-squared explained</A>
 
### Precision, Recall
<details>
  <summary>Important Formulae</summary>
  <ul>
   <li> Sensitivity = True Positive Rate = TP/(TP+FN)
   <li> Specificity = 1 - False Positive Rate = 1 - FP/(FP+TN) = TN/(FP+TN)
   <li> Precision =  TP/(TP+FP)
   <li> Recall = TP/(TP+FN)
   <li> F1-score = 2*Precision*Recall/(Precision + Recall)
  </ul>
</details>

 - [ ] <A HREF="https://www.youtube.com/watch?v=4jRBRDbJemM">ROC and AUC!</A>
 - [ ] <A HREF="https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/">How to Use ROC Curves and Precision-Recall Curves for Classification in Python</A>
 - F1 score, specificity, sensitivity

### Gradient Descent
 - [ ] <A HREF="https://www.youtube.com/watch?v=vMh0zPT0tLI">Stochastic Gradient Descent</A>
 
### Decision Trees & Random Forests
 - [ ] <A HREF="https://www.youtube.com/watch?v=_L39rN6gz7Y">Decision and Classification Trees</A>
 - [ ] <A HREF="https://www.youtube.com/watch?v=g9c66TUylZ4">Regression Trees</A>
 - [ ] <A HREF="https://www.youtube.com/watch?v=wpNl-JwwplA">Decision Trees, Part 2 - Feature Selection and Missing Data</A>
 - [ ] <A HREF="https://www.youtube.com/watch?v=D0efHEJsfHo">How to Prune Regression Trees</A>
 - [ ] <A HREF="https://www.youtube.com/watch?v=J4Wdy0Wc_xQ">Random Forests Part 1 - Building, Using and Evaluating</A>
 - [ ] <A HREF="https://www.geeksforgeeks.org/python-decision-tree-regression-using-sklearn/?ref=rp">Python | Decision Tree Regression using sklearn - GeeksforGeeks</A>
 
### Loss functions
 - [ ] <A HREF="https://www.youtube.com/watch?v=gIx974WtVb4">Why do we need Cross Entropy Loss? (Visualized)</A>

### L1, L2 Regression
 - [ ] <A HREF="https://www.youtube.com/watch?v=Xm2C_gTAl8c">Ridge vs Lasso Regression, Visualized</A>
 - [ ] <A HREF="https://www.youtube.com/watch?v=Q81RR3yKn30">Regularization Part 1: Ridge (L2) Regression</A>
 - [ ] <A HREF="https://www.youtube.com/watch?v=NGf0voTMlcs">Regularization Part 2: Lasso (L1) Regression</A>
 - [ ] <A HREF="https://www.youtube.com/watch?v=1dKRdX9bfIo">Regularization Part 3: Elastic Net Regression</A>
 - [ ] <A HREF="https://stats.stackexchange.com/questions/163388/why-is-the-l2-regularization-equivalent-to-gaussian-prior">regression - Why is the L2 regularization equivalent to Gaussian prior? - Cross Validated</A>
 - [ ] <A HREF="https://stats.stackexchange.com/questions/45643/why-l1-norm-for-sparse-models">regression - Why L1 norm for sparse models - Cross Validated</A>
 
### PCA, SVM, LDA
 - [ ] <A HREF="https://www.youtube.com/watch?v=HMOI_lkzW08">PCA main ideas in only 5 minutes</A>
 - [ ] <A HREF="https://www.youtube.com/watch?v=5HNr_j6LmPc">Visual Explanation of Principal Component Analysis, Covariance, SVD</A>
 - [ ] <A HREF="https://www.youtube.com/watch?v=FgakZw6K1QQ">Principal Component Analysis (PCA), Step-by-Step</A>
 - [ ] <A HREF="https://www.youtube.com/watch?v=efR1C6CvhmE">Support Vector Machines</A>
 - [ ] <A HREF="https://www.youtube.com/watch?v=azXCzI57Yfc">Linear Discriminant Analysis (LDA) clearly explained.</A>
 
### Boosting
 - [ ] <A HREF="https://www.youtube.com/watch?v=OtD8wVaFm6E">XGBoost Part 1: Regression</A>
 - [ ] <A HREF="https://www.youtube.com/watch?v=LsK-xG1cLYA">AdaBoost</A>
 - [ ] <A HREF="https://www.youtube.com/watch?v=3CC4N4z3GJc">Gradient Boost Part 1: Regression Main Ideas</A>

### Quantiles
 - [ ] <A HREF="https://www.youtube.com/watch?v=okjYjClSjOg">Quantile-Quantile Plots (QQ plots)</A>
 - [ ] <A HREF="https://www.youtube.com/watch?v=IFKQLDmRK0Y">Quantiles and Percentiles</A>

### Clustering
 - [ ] <A HREF="https://www.youtube.com/watch?v=7xHsRkOdVwo">Hierarchical Clustering</A>
 - [ ] <A HREF="https://www.youtube.com/watch?v=4b5d3muPQmA">K-means clustering</A>

### Neural Networks
 - [ ] <A HREF="https://machinelearningmastery.com/train-test-split-for-evaluating-machine-learning-algorithms/">Train-test splitting, Stratification</A>
 - [ ] <A HREF="https://www.analyticsvidhya.com/blog/2018/04/fundamentals-deep-learning-regularization-techniques/">Regularization, Dropout, Early Stopping</A>
 - [ ] <A HREF="https://machinelearningmastery.com/train-test-split-for-evaluating-machine-learning-algorithms/">Train-test splitting, Stratification</A>
 - [ ] <A HREF="https://www.youtube.com/watch?v=m8pOnJxOcqY">Convolution Neural Networks - EXPLAINED</A>

### Feature Transformation

 - [ ] <A HREF="https://datascience.stackexchange.com/questions/24452/in-supervised-learning-why-is-it-bad-to-have-correlated-features">correlation - In supervised learning, why is it bad to have correlated features? - Data Science Stack Exchange</A>
 - [ ] <A HREF="https://christophm.github.io/interpretable-ml-book/interaction.html">5.4 Feature Interaction | Interpretable Machine Learning</A>
 - [ ] <A HREF="https://medium.com/vickdata/four-feature-types-and-how-to-transform-them-for-machine-learning-8693e1c24e80">Feature Transformation for Machine Learning, a Beginners Guide | by Rebecca Vickery | vickdata | Medium</A>
 - [ ] <A HREF="https://towardsdatascience.com/apache-spark-mllib-tutorial-7aba8a1dce6e">Feature Transformation. How to handle different feature types… | by Ali Masri | Towards Data Science</A> 

### Python Pandas
 - [ ] <A HREF="https://www.youtube.com/watch?v=txMdrV1Ut64">(2) Python Pandas Tutorial (Part 8): Grouping and Aggregating - Analyzing and Exploring Your Data</A>
 - [ ] <A HREF="https://www.youtube.com/watch?v=zmdjNSmRXF4&list=PL-osiE80TeTsWmV9i9c58mdDCSskIFdDS&index=2">(2) Python Pandas Tutorial (Part 2): DataFrame and Series Basics - Selecting Rows and Columns</A>
